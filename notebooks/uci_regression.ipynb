{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optbnn.gp.models.gpr import GPR\n",
    "from optbnn.gp import kernels, mean_functions, priors\n",
    "from optbnn.bnn.reparam_nets import GaussianMLPReparameterization\n",
    "from optbnn.bnn.nets.mlp import MLP\n",
    "from optbnn.bnn.likelihoods import LikGaussian\n",
    "from optbnn.bnn.priors import FixedGaussianPrior, OptimGaussianPrior\n",
    "from optbnn.prior_mappers.wasserstein_mapper import MapperWasserstein, WassersteinDistance\n",
    "from optbnn.utils.rand_generators import MeasureSetGenerator, GridGenerator\n",
    "from optbnn.utils.normalization import normalize_data\n",
    "from optbnn.utils.exp_utils import get_input_range\n",
    "from optbnn.metrics.sampling import compute_rhat_regression\n",
    "from optbnn.metrics import uncertainty as uncertainty_metrics\n",
    "from optbnn.sgmcmc_bayes_net.regression_net import RegressionNet\n",
    "from optbnn.utils import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123\n",
    "util.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network architecture\n",
    "n_units = 100\n",
    "n_hidden = 1\n",
    "activation_fn = \"tanh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configurations\n",
    "n_splits = 10\n",
    "dataset = \"boston\"\n",
    "data_dir = \"./data/uci\"\n",
    "noise_var = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimized Gaussian Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = \"./exp/uci/optim_gaussian\"\n",
    "util.ensure_dir(out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Optimize the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 200\n",
    "lr = 0.05\n",
    "n_samples = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split 0 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 11.1247\n",
      ">>> Iteration #  10: Wasserstein Dist 4.0591\n",
      ">>> Iteration #  20: Wasserstein Dist 2.9549\n",
      ">>> Iteration #  30: Wasserstein Dist 4.4276\n",
      ">>> Iteration #  40: Wasserstein Dist 3.8298\n",
      ">>> Iteration #  50: Wasserstein Dist 2.5937\n",
      ">>> Iteration #  60: Wasserstein Dist 3.3104\n",
      ">>> Iteration #  70: Wasserstein Dist 1.5923\n",
      ">>> Iteration #  80: Wasserstein Dist 2.4809\n",
      ">>> Iteration #  90: Wasserstein Dist 1.8494\n",
      ">>> Iteration # 100: Wasserstein Dist 2.6735\n",
      ">>> Iteration # 110: Wasserstein Dist 1.8528\n",
      ">>> Iteration # 120: Wasserstein Dist 1.8654\n",
      ">>> Iteration # 130: Wasserstein Dist 1.6288\n",
      ">>> Iteration # 140: Wasserstein Dist 1.7169\n",
      ">>> Iteration # 150: Wasserstein Dist 2.2507\n",
      ">>> Iteration # 160: Wasserstein Dist 2.1141\n",
      ">>> Iteration # 170: Wasserstein Dist 0.6198\n",
      ">>> Iteration # 180: Wasserstein Dist 0.8857\n",
      ">>> Iteration # 190: Wasserstein Dist 2.3736\n",
      ">>> Iteration # 200: Wasserstein Dist 1.2547\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/0/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 1 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 10.6226\n",
      ">>> Iteration #  10: Wasserstein Dist 4.5198\n",
      ">>> Iteration #  20: Wasserstein Dist 3.2973\n",
      ">>> Iteration #  30: Wasserstein Dist 3.3741\n",
      ">>> Iteration #  40: Wasserstein Dist 3.0168\n",
      ">>> Iteration #  50: Wasserstein Dist 2.3837\n",
      ">>> Iteration #  60: Wasserstein Dist 2.7496\n",
      ">>> Iteration #  70: Wasserstein Dist 2.1963\n",
      ">>> Iteration #  80: Wasserstein Dist 2.6902\n",
      ">>> Iteration #  90: Wasserstein Dist 1.5283\n",
      ">>> Iteration # 100: Wasserstein Dist 1.7287\n",
      ">>> Iteration # 110: Wasserstein Dist 2.3396\n",
      ">>> Iteration # 120: Wasserstein Dist 3.0797\n",
      ">>> Iteration # 130: Wasserstein Dist 1.8809\n",
      ">>> Iteration # 140: Wasserstein Dist 1.5095\n",
      ">>> Iteration # 150: Wasserstein Dist 1.2466\n",
      ">>> Iteration # 160: Wasserstein Dist 0.4438\n",
      ">>> Iteration # 170: Wasserstein Dist 1.5146\n",
      ">>> Iteration # 180: Wasserstein Dist 1.4798\n",
      ">>> Iteration # 190: Wasserstein Dist 0.8752\n",
      ">>> Iteration # 200: Wasserstein Dist 0.8334\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/1/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 2 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 12.3219\n",
      ">>> Iteration #  10: Wasserstein Dist 5.1446\n",
      ">>> Iteration #  20: Wasserstein Dist 4.7099\n",
      ">>> Iteration #  30: Wasserstein Dist 3.3071\n",
      ">>> Iteration #  40: Wasserstein Dist 3.7197\n",
      ">>> Iteration #  50: Wasserstein Dist 2.6513\n",
      ">>> Iteration #  60: Wasserstein Dist 2.6524\n",
      ">>> Iteration #  70: Wasserstein Dist 0.0718\n",
      ">>> Iteration #  80: Wasserstein Dist 4.1098\n",
      ">>> Iteration #  90: Wasserstein Dist 2.0518\n",
      ">>> Iteration # 100: Wasserstein Dist 2.5438\n",
      ">>> Iteration # 110: Wasserstein Dist 2.8054\n",
      ">>> Iteration # 120: Wasserstein Dist 2.9475\n",
      ">>> Iteration # 130: Wasserstein Dist 2.3545\n",
      ">>> Iteration # 140: Wasserstein Dist 1.7858\n",
      ">>> Iteration # 150: Wasserstein Dist 0.5852\n",
      ">>> Iteration # 160: Wasserstein Dist 3.1313\n",
      ">>> Iteration # 170: Wasserstein Dist 2.6009\n",
      ">>> Iteration # 180: Wasserstein Dist 0.6311\n",
      ">>> Iteration # 190: Wasserstein Dist 1.5420\n",
      ">>> Iteration # 200: Wasserstein Dist 1.2429\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/2/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 3 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 11.4784\n",
      ">>> Iteration #  10: Wasserstein Dist 5.2720\n",
      ">>> Iteration #  20: Wasserstein Dist 4.0316\n",
      ">>> Iteration #  30: Wasserstein Dist 2.8056\n",
      ">>> Iteration #  40: Wasserstein Dist 3.0210\n",
      ">>> Iteration #  50: Wasserstein Dist 3.4694\n",
      ">>> Iteration #  60: Wasserstein Dist 2.9896\n",
      ">>> Iteration #  70: Wasserstein Dist 2.9093\n",
      ">>> Iteration #  80: Wasserstein Dist 2.4956\n",
      ">>> Iteration #  90: Wasserstein Dist 1.8986\n",
      ">>> Iteration # 100: Wasserstein Dist 1.0543\n",
      ">>> Iteration # 110: Wasserstein Dist 1.5081\n",
      ">>> Iteration # 120: Wasserstein Dist 1.6678\n",
      ">>> Iteration # 130: Wasserstein Dist 1.7835\n",
      ">>> Iteration # 140: Wasserstein Dist 2.6022\n",
      ">>> Iteration # 150: Wasserstein Dist 2.5422\n",
      ">>> Iteration # 160: Wasserstein Dist 1.6505\n",
      ">>> Iteration # 170: Wasserstein Dist 1.0601\n",
      ">>> Iteration # 180: Wasserstein Dist 1.8807\n",
      ">>> Iteration # 190: Wasserstein Dist 1.5292\n",
      ">>> Iteration # 200: Wasserstein Dist 0.6644\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/3/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 4 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 10.5772\n",
      ">>> Iteration #  10: Wasserstein Dist 4.9574\n",
      ">>> Iteration #  20: Wasserstein Dist 3.0600\n",
      ">>> Iteration #  30: Wasserstein Dist 3.2068\n",
      ">>> Iteration #  40: Wasserstein Dist 2.4174\n",
      ">>> Iteration #  50: Wasserstein Dist 2.2141\n",
      ">>> Iteration #  60: Wasserstein Dist 1.8271\n",
      ">>> Iteration #  70: Wasserstein Dist 3.0403\n",
      ">>> Iteration #  80: Wasserstein Dist 1.1383\n",
      ">>> Iteration #  90: Wasserstein Dist -0.2886\n",
      ">>> Iteration # 100: Wasserstein Dist 1.0441\n",
      ">>> Iteration # 110: Wasserstein Dist 3.3369\n",
      ">>> Iteration # 120: Wasserstein Dist 1.2181\n",
      ">>> Iteration # 130: Wasserstein Dist 1.0480\n",
      ">>> Iteration # 140: Wasserstein Dist 1.2874\n",
      ">>> Iteration # 150: Wasserstein Dist 2.0664\n",
      ">>> Iteration # 160: Wasserstein Dist 1.7957\n",
      ">>> Iteration # 170: Wasserstein Dist 0.9338\n",
      ">>> Iteration # 180: Wasserstein Dist 1.7228\n",
      ">>> Iteration # 190: Wasserstein Dist 1.8337\n",
      ">>> Iteration # 200: Wasserstein Dist 1.6725\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/4/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 5 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 10.6651\n",
      ">>> Iteration #  10: Wasserstein Dist 4.3773\n",
      ">>> Iteration #  20: Wasserstein Dist 4.5948\n",
      ">>> Iteration #  30: Wasserstein Dist 2.2017\n",
      ">>> Iteration #  40: Wasserstein Dist 2.3490\n",
      ">>> Iteration #  50: Wasserstein Dist 2.7157\n",
      ">>> Iteration #  60: Wasserstein Dist 2.6472\n",
      ">>> Iteration #  70: Wasserstein Dist 2.1707\n",
      ">>> Iteration #  80: Wasserstein Dist 1.5089\n",
      ">>> Iteration #  90: Wasserstein Dist 1.7723\n",
      ">>> Iteration # 100: Wasserstein Dist 2.9066\n",
      ">>> Iteration # 110: Wasserstein Dist 1.5031\n",
      ">>> Iteration # 120: Wasserstein Dist 0.2895\n",
      ">>> Iteration # 130: Wasserstein Dist 2.7254\n",
      ">>> Iteration # 140: Wasserstein Dist 0.7494\n",
      ">>> Iteration # 150: Wasserstein Dist 1.2076\n",
      ">>> Iteration # 160: Wasserstein Dist 0.7274\n",
      ">>> Iteration # 170: Wasserstein Dist 1.8121\n",
      ">>> Iteration # 180: Wasserstein Dist 1.5673\n",
      ">>> Iteration # 190: Wasserstein Dist 1.4312\n",
      ">>> Iteration # 200: Wasserstein Dist 0.2993\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/5/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 6 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 11.3920\n",
      ">>> Iteration #  10: Wasserstein Dist 5.0924\n",
      ">>> Iteration #  20: Wasserstein Dist 4.4781\n",
      ">>> Iteration #  30: Wasserstein Dist 4.2851\n",
      ">>> Iteration #  40: Wasserstein Dist 3.1861\n",
      ">>> Iteration #  50: Wasserstein Dist 3.7172\n",
      ">>> Iteration #  60: Wasserstein Dist 3.1010\n",
      ">>> Iteration #  70: Wasserstein Dist 2.2679\n",
      ">>> Iteration #  80: Wasserstein Dist 1.7014\n",
      ">>> Iteration #  90: Wasserstein Dist 2.6023\n",
      ">>> Iteration # 100: Wasserstein Dist 1.5847\n",
      ">>> Iteration # 110: Wasserstein Dist 0.6740\n",
      ">>> Iteration # 120: Wasserstein Dist 2.7818\n",
      ">>> Iteration # 130: Wasserstein Dist 0.7466\n",
      ">>> Iteration # 140: Wasserstein Dist 2.0511\n",
      ">>> Iteration # 150: Wasserstein Dist 2.2095\n",
      ">>> Iteration # 160: Wasserstein Dist 1.7812\n",
      ">>> Iteration # 170: Wasserstein Dist 0.7781\n",
      ">>> Iteration # 180: Wasserstein Dist 0.9869\n",
      ">>> Iteration # 190: Wasserstein Dist 1.2890\n",
      ">>> Iteration # 200: Wasserstein Dist 0.0336\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/6/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 7 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 11.4864\n",
      ">>> Iteration #  10: Wasserstein Dist 4.7492\n",
      ">>> Iteration #  20: Wasserstein Dist 3.8987\n",
      ">>> Iteration #  30: Wasserstein Dist 2.2069\n",
      ">>> Iteration #  40: Wasserstein Dist 2.2866\n",
      ">>> Iteration #  50: Wasserstein Dist 2.3342\n",
      ">>> Iteration #  60: Wasserstein Dist 3.1059\n",
      ">>> Iteration #  70: Wasserstein Dist 1.7924\n",
      ">>> Iteration #  80: Wasserstein Dist 2.0134\n",
      ">>> Iteration #  90: Wasserstein Dist 2.9011\n",
      ">>> Iteration # 100: Wasserstein Dist 1.3248\n",
      ">>> Iteration # 110: Wasserstein Dist 1.3776\n",
      ">>> Iteration # 120: Wasserstein Dist 2.7948\n",
      ">>> Iteration # 130: Wasserstein Dist 2.1632\n",
      ">>> Iteration # 140: Wasserstein Dist 1.5968\n",
      ">>> Iteration # 150: Wasserstein Dist 1.5188\n",
      ">>> Iteration # 160: Wasserstein Dist 0.5556\n",
      ">>> Iteration # 170: Wasserstein Dist 1.5558\n",
      ">>> Iteration # 180: Wasserstein Dist 2.7385\n",
      ">>> Iteration # 190: Wasserstein Dist 1.1295\n",
      ">>> Iteration # 200: Wasserstein Dist 1.1311\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/7/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 8 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 12.5135\n",
      ">>> Iteration #  10: Wasserstein Dist 3.7070\n",
      ">>> Iteration #  20: Wasserstein Dist 4.0949\n",
      ">>> Iteration #  30: Wasserstein Dist 3.2864\n",
      ">>> Iteration #  40: Wasserstein Dist 2.6143\n",
      ">>> Iteration #  50: Wasserstein Dist 2.8797\n",
      ">>> Iteration #  60: Wasserstein Dist 2.8894\n",
      ">>> Iteration #  70: Wasserstein Dist 3.0390\n",
      ">>> Iteration #  80: Wasserstein Dist 1.8726\n",
      ">>> Iteration #  90: Wasserstein Dist 1.2467\n",
      ">>> Iteration # 100: Wasserstein Dist 1.4998\n",
      ">>> Iteration # 110: Wasserstein Dist 1.9316\n",
      ">>> Iteration # 120: Wasserstein Dist 1.6600\n",
      ">>> Iteration # 130: Wasserstein Dist 1.9880\n",
      ">>> Iteration # 140: Wasserstein Dist 1.8844\n",
      ">>> Iteration # 150: Wasserstein Dist 1.2621\n",
      ">>> Iteration # 160: Wasserstein Dist 1.1370\n",
      ">>> Iteration # 170: Wasserstein Dist 0.8107\n",
      ">>> Iteration # 180: Wasserstein Dist 2.0486\n",
      ">>> Iteration # 190: Wasserstein Dist 1.4054\n",
      ">>> Iteration # 200: Wasserstein Dist 1.8906\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/8/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n",
      "Loading split 9 of boston dataset\n",
      ">>> Iteration #   1: Wasserstein Dist 10.9393\n",
      ">>> Iteration #  10: Wasserstein Dist 4.1235\n",
      ">>> Iteration #  20: Wasserstein Dist 4.2987\n",
      ">>> Iteration #  30: Wasserstein Dist 3.1910\n",
      ">>> Iteration #  40: Wasserstein Dist 4.0777\n",
      ">>> Iteration #  50: Wasserstein Dist 3.8977\n",
      ">>> Iteration #  60: Wasserstein Dist 1.8944\n",
      ">>> Iteration #  70: Wasserstein Dist 2.1767\n",
      ">>> Iteration #  80: Wasserstein Dist 2.2539\n",
      ">>> Iteration #  90: Wasserstein Dist 1.7384\n",
      ">>> Iteration # 100: Wasserstein Dist 1.4151\n",
      ">>> Iteration # 110: Wasserstein Dist 1.3560\n",
      ">>> Iteration # 120: Wasserstein Dist 1.7849\n",
      ">>> Iteration # 130: Wasserstein Dist 2.8433\n",
      ">>> Iteration # 140: Wasserstein Dist 1.8852\n",
      ">>> Iteration # 150: Wasserstein Dist 1.3242\n",
      ">>> Iteration # 160: Wasserstein Dist 2.4081\n",
      ">>> Iteration # 170: Wasserstein Dist 2.8407\n",
      ">>> Iteration # 180: Wasserstein Dist 1.8828\n",
      ">>> Iteration # 190: Wasserstein Dist 0.5759\n",
      ">>> Iteration # 200: Wasserstein Dist 0.9415\n",
      "Saved intermediate wasserstein values in: ./exp/uci/optim_gaussian/9/wsr_intermediate_values.log\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for split_id in range(n_splits):\n",
    "    print(\"Loading split {} of {} dataset\".format(split_id, dataset))\n",
    "    # Load the dataset\n",
    "    saved_dir = os.path.join(out_dir, str(split_id))\n",
    "    X_train, y_train, X_test, y_test = util.load_uci_data(\n",
    "            data_dir, split_id, dataset)\n",
    "    X_train_, y_train_, X_test_, y_test_, y_mean, y_std = normalize_data(\n",
    "            X_train, y_train, X_test, y_test)\n",
    "    x_min, x_max = get_input_range(X_train_, X_test_)\n",
    "    input_dim, output_dim = int(X_train.shape[-1]), 1\n",
    "    \n",
    "    # Initialize the measurement set generator\n",
    "    rand_generator = MeasureSetGenerator(X_train_, x_min, x_max, 0.7)\n",
    "    \n",
    "    # Initialize the mean and covariance function of the target hierarchical GP prior\n",
    "    mean = mean_functions.Zero()\n",
    "    \n",
    "    lengthscale = math.sqrt(2. * input_dim)\n",
    "    variance = 1.\n",
    "    kernel = kernels.RBF(input_dim=input_dim,\n",
    "                         lengthscales=torch.tensor([lengthscale], dtype=torch.double),\n",
    "                         variance=torch.tensor([variance], dtype=torch.double), ARD=True)\n",
    "\n",
    "    # Place hyper-priors on lengthscales and variances\n",
    "    kernel.lengthscales.prior = priors.LogNormal(\n",
    "            torch.ones([input_dim]) * math.log(lengthscale),\n",
    "            torch.ones([input_dim]) * 1.)\n",
    "    kernel.variance.prior = priors.LogNormal(\n",
    "            torch.ones([1]) * 0.1,\n",
    "            torch.ones([1]) * 1.)\n",
    "        \n",
    "    # Initialize the GP model\n",
    "    gp = GPR(X=torch.from_numpy(X_train_), Y=torch.from_numpy(y_train_).reshape([-1, 1]),\n",
    "             kern=kernel, mean_function=mean)\n",
    "    gp.likelihood.variance.set(noise_var)\n",
    "    \n",
    "    # Initialize tunable MLP prior\n",
    "    hidden_dims = [n_units] * n_hidden\n",
    "    mlp_reparam = GaussianMLPReparameterization(input_dim, output_dim,\n",
    "        hidden_dims, activation_fn, scaled_variance=True)\n",
    "    \n",
    "    mapper = MapperWasserstein(gp, mlp_reparam, rand_generator, out_dir=saved_dir,\n",
    "                               output_dim=output_dim, n_data=100,\n",
    "                               wasserstein_steps=(0, 200),\n",
    "                               wasserstein_lr=0.02,\n",
    "                               logger=None, wasserstein_thres=0.1,\n",
    "                               n_gpu=0, gpu_gp=False)\n",
    "    \n",
    "    w_hist = mapper.optimize(num_iters=num_iters, n_samples=n_samples,\n",
    "                             lr=lr, print_every=10, save_ckpt_every=10, debug=True)\n",
    "    path = os.path.join(saved_dir, \"wsr_values.log\")\n",
    "    np.savetxt(path, w_hist, fmt='%.6e')\n",
    "    print(\"----\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the convergence\n",
    "wdist_data = []\n",
    "for i in range(0, n_splits):\n",
    "    wdist_file = os.path.join(out_dir, str(i), \"wsr_values.log\")\n",
    "    wdist_data.append(np.loadtxt(wdist_file))\n",
    "\n",
    "wdist_vals = np.stack(wdist_data)\n",
    "x = np.arange(wdist_vals.shape[1])\n",
    "mean = wdist_vals.mean(0)\n",
    "std = wdist_vals.std(0)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "plt.plot(x[::2], mean[::2], \"-ok\", ms=2)\n",
    "plt.fill_between(x[::2], mean[::2] - std[::2],\n",
    "                 mean[::2] + std[::2], alpha=0.18, color=\"k\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$W_1(p_{gp}, p_{nn})$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Posterior Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the SGHMC sampler\n",
    "sampling_configs = {\n",
    "    \"batch_size\": 32,\n",
    "    \"num_samples\": 40,\n",
    "    \"n_discarded\": 10,\n",
    "    \"num_burn_in_steps\": 2000,\n",
    "    \"keep_every\": 2000,\n",
    "    \"lr\": 1e-2,\n",
    "    \"num_chains\": 4,\n",
    "    \"mdecay\": 1e-2,\n",
    "    \"print_every_n_samples\": 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split 0 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2758e+00 RMSE = 1.8902e+00 \n",
      "Samples #    10 : NLL =  2.2691e+00 RMSE = 1.7746e+00 \n",
      "Samples #    15 : NLL =  2.2656e+00 RMSE = 1.7515e+00 \n",
      "Samples #    20 : NLL =  2.2697e+00 RMSE = 1.7667e+00 \n",
      "Samples #    25 : NLL =  2.2691e+00 RMSE = 1.7631e+00 \n",
      "Samples #    30 : NLL =  2.2702e+00 RMSE = 1.7571e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2705e+00 RMSE = 1.7514e+00 \n",
      "Samples #    40 : NLL =  2.2693e+00 RMSE = 1.7497e+00 \n",
      "Samples #    45 : NLL =  2.2678e+00 RMSE = 1.7410e+00 \n",
      "Samples #    50 : NLL =  2.2673e+00 RMSE = 1.7387e+00 \n",
      "Samples #    55 : NLL =  2.2660e+00 RMSE = 1.7337e+00 \n",
      "Samples #    60 : NLL =  2.2660e+00 RMSE = 1.7334e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2664e+00 RMSE = 1.7351e+00 \n",
      "Samples #    70 : NLL =  2.2668e+00 RMSE = 1.7368e+00 \n",
      "Samples #    75 : NLL =  2.2681e+00 RMSE = 1.7370e+00 \n",
      "Samples #    80 : NLL =  2.2680e+00 RMSE = 1.7355e+00 \n",
      "Samples #    85 : NLL =  2.2677e+00 RMSE = 1.7336e+00 \n",
      "Samples #    90 : NLL =  2.2680e+00 RMSE = 1.7361e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2681e+00 RMSE = 1.7390e+00 \n",
      "Samples #   100 : NLL =  2.2680e+00 RMSE = 1.7382e+00 \n",
      "Samples #   105 : NLL =  2.2677e+00 RMSE = 1.7376e+00 \n",
      "Samples #   110 : NLL =  2.2679e+00 RMSE = 1.7374e+00 \n",
      "Samples #   115 : NLL =  2.2677e+00 RMSE = 1.7369e+00 \n",
      "Samples #   120 : NLL =  2.2675e+00 RMSE = 1.7375e+00 \n",
      "R-hat: mean 1.0133 std 0.0217\n",
      "> RMSE = 2.3857 | NLL = 2.4005\n",
      "Loading split 1 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2683e+00 RMSE = 1.9030e+00 \n",
      "Samples #    10 : NLL =  2.2676e+00 RMSE = 1.8086e+00 \n",
      "Samples #    15 : NLL =  2.2634e+00 RMSE = 1.7396e+00 \n",
      "Samples #    20 : NLL =  2.2603e+00 RMSE = 1.7211e+00 \n",
      "Samples #    25 : NLL =  2.2615e+00 RMSE = 1.7273e+00 \n",
      "Samples #    30 : NLL =  2.2623e+00 RMSE = 1.7250e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2624e+00 RMSE = 1.7236e+00 \n",
      "Samples #    40 : NLL =  2.2609e+00 RMSE = 1.7141e+00 \n",
      "Samples #    45 : NLL =  2.2606e+00 RMSE = 1.7053e+00 \n",
      "Samples #    50 : NLL =  2.2604e+00 RMSE = 1.6975e+00 \n",
      "Samples #    55 : NLL =  2.2601e+00 RMSE = 1.6886e+00 \n",
      "Samples #    60 : NLL =  2.2595e+00 RMSE = 1.6860e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2594e+00 RMSE = 1.6832e+00 \n",
      "Samples #    70 : NLL =  2.2599e+00 RMSE = 1.6826e+00 \n",
      "Samples #    75 : NLL =  2.2596e+00 RMSE = 1.6825e+00 \n",
      "Samples #    80 : NLL =  2.2593e+00 RMSE = 1.6855e+00 \n",
      "Samples #    85 : NLL =  2.2589e+00 RMSE = 1.6847e+00 \n",
      "Samples #    90 : NLL =  2.2588e+00 RMSE = 1.6819e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2581e+00 RMSE = 1.6755e+00 \n",
      "Samples #   100 : NLL =  2.2585e+00 RMSE = 1.6770e+00 \n",
      "Samples #   105 : NLL =  2.2590e+00 RMSE = 1.6787e+00 \n",
      "Samples #   110 : NLL =  2.2595e+00 RMSE = 1.6825e+00 \n",
      "Samples #   115 : NLL =  2.2596e+00 RMSE = 1.6838e+00 \n",
      "Samples #   120 : NLL =  2.2596e+00 RMSE = 1.6841e+00 \n",
      "R-hat: mean 1.0087 std 0.0206\n",
      "> RMSE = 2.4616 | NLL = 2.4216\n",
      "Loading split 2 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2656e+00 RMSE = 1.9168e+00 \n",
      "Samples #    10 : NLL =  2.2556e+00 RMSE = 1.7729e+00 \n",
      "Samples #    15 : NLL =  2.2570e+00 RMSE = 1.7809e+00 \n",
      "Samples #    20 : NLL =  2.2574e+00 RMSE = 1.7669e+00 \n",
      "Samples #    25 : NLL =  2.2570e+00 RMSE = 1.7540e+00 \n",
      "Samples #    30 : NLL =  2.2575e+00 RMSE = 1.7409e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2575e+00 RMSE = 1.7414e+00 \n",
      "Samples #    40 : NLL =  2.2573e+00 RMSE = 1.7391e+00 \n",
      "Samples #    45 : NLL =  2.2575e+00 RMSE = 1.7431e+00 \n",
      "Samples #    50 : NLL =  2.2565e+00 RMSE = 1.7383e+00 \n",
      "Samples #    55 : NLL =  2.2559e+00 RMSE = 1.7344e+00 \n",
      "Samples #    60 : NLL =  2.2557e+00 RMSE = 1.7340e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2551e+00 RMSE = 1.7317e+00 \n",
      "Samples #    70 : NLL =  2.2553e+00 RMSE = 1.7272e+00 \n",
      "Samples #    75 : NLL =  2.2553e+00 RMSE = 1.7280e+00 \n",
      "Samples #    80 : NLL =  2.2546e+00 RMSE = 1.7257e+00 \n",
      "Samples #    85 : NLL =  2.2538e+00 RMSE = 1.7227e+00 \n",
      "Samples #    90 : NLL =  2.2540e+00 RMSE = 1.7197e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2541e+00 RMSE = 1.7198e+00 \n",
      "Samples #   100 : NLL =  2.2539e+00 RMSE = 1.7167e+00 \n",
      "Samples #   105 : NLL =  2.2547e+00 RMSE = 1.7195e+00 \n",
      "Samples #   110 : NLL =  2.2549e+00 RMSE = 1.7179e+00 \n",
      "Samples #   115 : NLL =  2.2542e+00 RMSE = 1.7139e+00 \n",
      "Samples #   120 : NLL =  2.2543e+00 RMSE = 1.7147e+00 \n",
      "R-hat: mean 1.0130 std 0.0460\n",
      "> RMSE = 2.0982 | NLL = 2.3557\n",
      "Loading split 3 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2587e+00 RMSE = 1.9161e+00 \n",
      "Samples #    10 : NLL =  2.2491e+00 RMSE = 1.8199e+00 \n",
      "Samples #    15 : NLL =  2.2508e+00 RMSE = 1.8036e+00 \n",
      "Samples #    20 : NLL =  2.2483e+00 RMSE = 1.7792e+00 \n",
      "Samples #    25 : NLL =  2.2487e+00 RMSE = 1.7720e+00 \n",
      "Samples #    30 : NLL =  2.2476e+00 RMSE = 1.7553e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2472e+00 RMSE = 1.7425e+00 \n",
      "Samples #    40 : NLL =  2.2466e+00 RMSE = 1.7395e+00 \n",
      "Samples #    45 : NLL =  2.2456e+00 RMSE = 1.7347e+00 \n",
      "Samples #    50 : NLL =  2.2460e+00 RMSE = 1.7366e+00 \n",
      "Samples #    55 : NLL =  2.2455e+00 RMSE = 1.7339e+00 \n",
      "Samples #    60 : NLL =  2.2456e+00 RMSE = 1.7330e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2458e+00 RMSE = 1.7280e+00 \n",
      "Samples #    70 : NLL =  2.2472e+00 RMSE = 1.7274e+00 \n",
      "Samples #    75 : NLL =  2.2468e+00 RMSE = 1.7221e+00 \n",
      "Samples #    80 : NLL =  2.2470e+00 RMSE = 1.7215e+00 \n",
      "Samples #    85 : NLL =  2.2468e+00 RMSE = 1.7181e+00 \n",
      "Samples #    90 : NLL =  2.2470e+00 RMSE = 1.7185e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2470e+00 RMSE = 1.7181e+00 \n",
      "Samples #   100 : NLL =  2.2469e+00 RMSE = 1.7174e+00 \n",
      "Samples #   105 : NLL =  2.2459e+00 RMSE = 1.7133e+00 \n",
      "Samples #   110 : NLL =  2.2461e+00 RMSE = 1.7137e+00 \n",
      "Samples #   115 : NLL =  2.2465e+00 RMSE = 1.7167e+00 \n",
      "Samples #   120 : NLL =  2.2473e+00 RMSE = 1.7188e+00 \n",
      "R-hat: mean 1.0055 std 0.0165\n",
      "> RMSE = 2.5340 | NLL = 2.3985\n",
      "Loading split 4 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2211e+00 RMSE = 1.7905e+00 \n",
      "Samples #    10 : NLL =  2.2258e+00 RMSE = 1.7298e+00 \n",
      "Samples #    15 : NLL =  2.2211e+00 RMSE = 1.6695e+00 \n",
      "Samples #    20 : NLL =  2.2198e+00 RMSE = 1.6420e+00 \n",
      "Samples #    25 : NLL =  2.2200e+00 RMSE = 1.6406e+00 \n",
      "Samples #    30 : NLL =  2.2193e+00 RMSE = 1.6438e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2192e+00 RMSE = 1.6358e+00 \n",
      "Samples #    40 : NLL =  2.2194e+00 RMSE = 1.6311e+00 \n",
      "Samples #    45 : NLL =  2.2185e+00 RMSE = 1.6236e+00 \n",
      "Samples #    50 : NLL =  2.2184e+00 RMSE = 1.6245e+00 \n",
      "Samples #    55 : NLL =  2.2176e+00 RMSE = 1.6163e+00 \n",
      "Samples #    60 : NLL =  2.2187e+00 RMSE = 1.6190e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2183e+00 RMSE = 1.6182e+00 \n",
      "Samples #    70 : NLL =  2.2184e+00 RMSE = 1.6189e+00 \n",
      "Samples #    75 : NLL =  2.2187e+00 RMSE = 1.6210e+00 \n",
      "Samples #    80 : NLL =  2.2188e+00 RMSE = 1.6194e+00 \n",
      "Samples #    85 : NLL =  2.2194e+00 RMSE = 1.6187e+00 \n",
      "Samples #    90 : NLL =  2.2194e+00 RMSE = 1.6181e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2190e+00 RMSE = 1.6183e+00 \n",
      "Samples #   100 : NLL =  2.2188e+00 RMSE = 1.6164e+00 \n",
      "Samples #   105 : NLL =  2.2188e+00 RMSE = 1.6154e+00 \n",
      "Samples #   110 : NLL =  2.2187e+00 RMSE = 1.6132e+00 \n",
      "Samples #   115 : NLL =  2.2189e+00 RMSE = 1.6137e+00 \n",
      "Samples #   120 : NLL =  2.2191e+00 RMSE = 1.6176e+00 \n",
      "R-hat: mean 1.0112 std 0.0180\n",
      "> RMSE = 3.8330 | NLL = 2.6421\n",
      "Loading split 5 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2767e+00 RMSE = 1.9577e+00 \n",
      "Samples #    10 : NLL =  2.2702e+00 RMSE = 1.8505e+00 \n",
      "Samples #    15 : NLL =  2.2649e+00 RMSE = 1.8069e+00 \n",
      "Samples #    20 : NLL =  2.2606e+00 RMSE = 1.7701e+00 \n",
      "Samples #    25 : NLL =  2.2620e+00 RMSE = 1.7663e+00 \n",
      "Samples #    30 : NLL =  2.2599e+00 RMSE = 1.7573e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2592e+00 RMSE = 1.7475e+00 \n",
      "Samples #    40 : NLL =  2.2594e+00 RMSE = 1.7398e+00 \n",
      "Samples #    45 : NLL =  2.2577e+00 RMSE = 1.7294e+00 \n",
      "Samples #    50 : NLL =  2.2592e+00 RMSE = 1.7327e+00 \n",
      "Samples #    55 : NLL =  2.2595e+00 RMSE = 1.7339e+00 \n",
      "Samples #    60 : NLL =  2.2601e+00 RMSE = 1.7389e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2601e+00 RMSE = 1.7369e+00 \n",
      "Samples #    70 : NLL =  2.2601e+00 RMSE = 1.7348e+00 \n",
      "Samples #    75 : NLL =  2.2599e+00 RMSE = 1.7328e+00 \n",
      "Samples #    80 : NLL =  2.2604e+00 RMSE = 1.7336e+00 \n",
      "Samples #    85 : NLL =  2.2607e+00 RMSE = 1.7350e+00 \n",
      "Samples #    90 : NLL =  2.2602e+00 RMSE = 1.7328e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2610e+00 RMSE = 1.7345e+00 \n",
      "Samples #   100 : NLL =  2.2606e+00 RMSE = 1.7331e+00 \n",
      "Samples #   105 : NLL =  2.2609e+00 RMSE = 1.7340e+00 \n",
      "Samples #   110 : NLL =  2.2612e+00 RMSE = 1.7358e+00 \n",
      "Samples #   115 : NLL =  2.2613e+00 RMSE = 1.7367e+00 \n",
      "Samples #   120 : NLL =  2.2609e+00 RMSE = 1.7366e+00 \n",
      "R-hat: mean 1.0154 std 0.0209\n",
      "> RMSE = 1.7339 | NLL = 2.3044\n",
      "Loading split 6 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2845e+00 RMSE = 1.9268e+00 \n",
      "Samples #    10 : NLL =  2.2820e+00 RMSE = 1.8355e+00 \n",
      "Samples #    15 : NLL =  2.2790e+00 RMSE = 1.7847e+00 \n",
      "Samples #    20 : NLL =  2.2775e+00 RMSE = 1.7608e+00 \n",
      "Samples #    25 : NLL =  2.2766e+00 RMSE = 1.7597e+00 \n",
      "Samples #    30 : NLL =  2.2784e+00 RMSE = 1.7531e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2776e+00 RMSE = 1.7458e+00 \n",
      "Samples #    40 : NLL =  2.2781e+00 RMSE = 1.7499e+00 \n",
      "Samples #    45 : NLL =  2.2763e+00 RMSE = 1.7394e+00 \n",
      "Samples #    50 : NLL =  2.2752e+00 RMSE = 1.7315e+00 \n",
      "Samples #    55 : NLL =  2.2744e+00 RMSE = 1.7213e+00 \n",
      "Samples #    60 : NLL =  2.2738e+00 RMSE = 1.7168e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2740e+00 RMSE = 1.7194e+00 \n",
      "Samples #    70 : NLL =  2.2738e+00 RMSE = 1.7206e+00 \n",
      "Samples #    75 : NLL =  2.2735e+00 RMSE = 1.7188e+00 \n",
      "Samples #    80 : NLL =  2.2731e+00 RMSE = 1.7182e+00 \n",
      "Samples #    85 : NLL =  2.2737e+00 RMSE = 1.7193e+00 \n",
      "Samples #    90 : NLL =  2.2739e+00 RMSE = 1.7243e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2739e+00 RMSE = 1.7244e+00 \n",
      "Samples #   100 : NLL =  2.2744e+00 RMSE = 1.7266e+00 \n",
      "Samples #   105 : NLL =  2.2748e+00 RMSE = 1.7292e+00 \n",
      "Samples #   110 : NLL =  2.2756e+00 RMSE = 1.7331e+00 \n",
      "Samples #   115 : NLL =  2.2760e+00 RMSE = 1.7343e+00 \n",
      "Samples #   120 : NLL =  2.2758e+00 RMSE = 1.7337e+00 \n",
      "R-hat: mean 1.0195 std 0.0306\n",
      "> RMSE = 1.7887 | NLL = 2.3298\n",
      "Loading split 7 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2701e+00 RMSE = 1.9115e+00 \n",
      "Samples #    10 : NLL =  2.2663e+00 RMSE = 1.8035e+00 \n",
      "Samples #    15 : NLL =  2.2631e+00 RMSE = 1.7724e+00 \n",
      "Samples #    20 : NLL =  2.2618e+00 RMSE = 1.7489e+00 \n",
      "Samples #    25 : NLL =  2.2609e+00 RMSE = 1.7365e+00 \n",
      "Samples #    30 : NLL =  2.2607e+00 RMSE = 1.7252e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2599e+00 RMSE = 1.7235e+00 \n",
      "Samples #    40 : NLL =  2.2602e+00 RMSE = 1.7244e+00 \n",
      "Samples #    45 : NLL =  2.2583e+00 RMSE = 1.7156e+00 \n",
      "Samples #    50 : NLL =  2.2580e+00 RMSE = 1.7087e+00 \n",
      "Samples #    55 : NLL =  2.2576e+00 RMSE = 1.7049e+00 \n",
      "Samples #    60 : NLL =  2.2587e+00 RMSE = 1.7049e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2580e+00 RMSE = 1.7007e+00 \n",
      "Samples #    70 : NLL =  2.2582e+00 RMSE = 1.7042e+00 \n",
      "Samples #    75 : NLL =  2.2577e+00 RMSE = 1.7001e+00 \n",
      "Samples #    80 : NLL =  2.2581e+00 RMSE = 1.7011e+00 \n",
      "Samples #    85 : NLL =  2.2583e+00 RMSE = 1.7017e+00 \n",
      "Samples #    90 : NLL =  2.2586e+00 RMSE = 1.7028e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2576e+00 RMSE = 1.6993e+00 \n",
      "Samples #   100 : NLL =  2.2573e+00 RMSE = 1.6954e+00 \n",
      "Samples #   105 : NLL =  2.2579e+00 RMSE = 1.6953e+00 \n",
      "Samples #   110 : NLL =  2.2581e+00 RMSE = 1.6971e+00 \n",
      "Samples #   115 : NLL =  2.2579e+00 RMSE = 1.6971e+00 \n",
      "Samples #   120 : NLL =  2.2586e+00 RMSE = 1.6995e+00 \n",
      "R-hat: mean 1.0256 std 0.0460\n",
      "> RMSE = 3.1674 | NLL = 2.4984\n",
      "Loading split 8 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2367e+00 RMSE = 1.7953e+00 \n",
      "Samples #    10 : NLL =  2.2424e+00 RMSE = 1.7569e+00 \n",
      "Samples #    15 : NLL =  2.2457e+00 RMSE = 1.7370e+00 \n",
      "Samples #    20 : NLL =  2.2452e+00 RMSE = 1.7251e+00 \n",
      "Samples #    25 : NLL =  2.2458e+00 RMSE = 1.7129e+00 \n",
      "Samples #    30 : NLL =  2.2468e+00 RMSE = 1.7063e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2444e+00 RMSE = 1.6953e+00 \n",
      "Samples #    40 : NLL =  2.2442e+00 RMSE = 1.6908e+00 \n",
      "Samples #    45 : NLL =  2.2451e+00 RMSE = 1.6971e+00 \n",
      "Samples #    50 : NLL =  2.2439e+00 RMSE = 1.6923e+00 \n",
      "Samples #    55 : NLL =  2.2448e+00 RMSE = 1.6957e+00 \n",
      "Samples #    60 : NLL =  2.2452e+00 RMSE = 1.6993e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2458e+00 RMSE = 1.6955e+00 \n",
      "Samples #    70 : NLL =  2.2453e+00 RMSE = 1.6929e+00 \n",
      "Samples #    75 : NLL =  2.2454e+00 RMSE = 1.6917e+00 \n",
      "Samples #    80 : NLL =  2.2452e+00 RMSE = 1.6885e+00 \n",
      "Samples #    85 : NLL =  2.2453e+00 RMSE = 1.6884e+00 \n",
      "Samples #    90 : NLL =  2.2453e+00 RMSE = 1.6886e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2448e+00 RMSE = 1.6857e+00 \n",
      "Samples #   100 : NLL =  2.2444e+00 RMSE = 1.6820e+00 \n",
      "Samples #   105 : NLL =  2.2451e+00 RMSE = 1.6845e+00 \n",
      "Samples #   110 : NLL =  2.2446e+00 RMSE = 1.6795e+00 \n",
      "Samples #   115 : NLL =  2.2442e+00 RMSE = 1.6777e+00 \n",
      "Samples #   120 : NLL =  2.2440e+00 RMSE = 1.6756e+00 \n",
      "R-hat: mean 1.0111 std 0.0231\n",
      "> RMSE = 3.4735 | NLL = 2.6189\n",
      "Loading split 9 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.2604e+00 RMSE = 1.8677e+00 \n",
      "Samples #    10 : NLL =  2.2574e+00 RMSE = 1.7948e+00 \n",
      "Samples #    15 : NLL =  2.2522e+00 RMSE = 1.7779e+00 \n",
      "Samples #    20 : NLL =  2.2512e+00 RMSE = 1.7659e+00 \n",
      "Samples #    25 : NLL =  2.2504e+00 RMSE = 1.7484e+00 \n",
      "Samples #    30 : NLL =  2.2501e+00 RMSE = 1.7507e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.2489e+00 RMSE = 1.7333e+00 \n",
      "Samples #    40 : NLL =  2.2491e+00 RMSE = 1.7317e+00 \n",
      "Samples #    45 : NLL =  2.2502e+00 RMSE = 1.7381e+00 \n",
      "Samples #    50 : NLL =  2.2500e+00 RMSE = 1.7348e+00 \n",
      "Samples #    55 : NLL =  2.2483e+00 RMSE = 1.7274e+00 \n",
      "Samples #    60 : NLL =  2.2483e+00 RMSE = 1.7271e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.2482e+00 RMSE = 1.7224e+00 \n",
      "Samples #    70 : NLL =  2.2477e+00 RMSE = 1.7206e+00 \n",
      "Samples #    75 : NLL =  2.2466e+00 RMSE = 1.7172e+00 \n",
      "Samples #    80 : NLL =  2.2472e+00 RMSE = 1.7183e+00 \n",
      "Samples #    85 : NLL =  2.2464e+00 RMSE = 1.7172e+00 \n",
      "Samples #    90 : NLL =  2.2460e+00 RMSE = 1.7152e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.2463e+00 RMSE = 1.7146e+00 \n",
      "Samples #   100 : NLL =  2.2461e+00 RMSE = 1.7106e+00 \n",
      "Samples #   105 : NLL =  2.2459e+00 RMSE = 1.7104e+00 \n",
      "Samples #   110 : NLL =  2.2454e+00 RMSE = 1.7082e+00 \n",
      "Samples #   115 : NLL =  2.2456e+00 RMSE = 1.7079e+00 \n",
      "Samples #   120 : NLL =  2.2463e+00 RMSE = 1.7119e+00 \n",
      "R-hat: mean 1.0098 std 0.0223\n",
      "> RMSE = 4.4936 | NLL = 2.7285\n"
     ]
    }
   ],
   "source": [
    "results = {\"rmse\": [], \"nll\": []}\n",
    "\n",
    "for split_id in range(n_splits):\n",
    "    print(\"Loading split {} of {} dataset\".format(split_id, dataset))\n",
    "    saved_dir = os.path.join(out_dir, str(split_id))\n",
    "    \n",
    "    # Load the dataset\n",
    "    X_train, y_train, X_test, y_test = util.load_uci_data(\n",
    "            data_dir, split_id, dataset)\n",
    "    input_dim, output_dim = int(X_train.shape[-1]), 1\n",
    "    \n",
    "    # Initialize the neural network and likelihood modules\n",
    "    net = MLP(input_dim, output_dim, [n_units] * n_hidden, activation_fn)\n",
    "    likelihood = LikGaussian(noise_var)\n",
    "    \n",
    "    # Load the optimized prior\n",
    "    ckpt_path = os.path.join(out_dir, str(split_id), \"ckpts\", \"it-{}.ckpt\".format(num_iters))\n",
    "    prior = OptimGaussianPrior(ckpt_path)\n",
    "    \n",
    "    # Initialize bayesian neural network with SGHMC sampler\n",
    "    saved_dir = os.path.join(out_dir, str(split_id))\n",
    "    bayes_net = RegressionNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "    \n",
    "    # Start sampling\n",
    "    bayes_net.sample_multi_chains(X_train, y_train, **sampling_configs)\n",
    "    pred_mean, pred_var, preds, raw_preds = bayes_net.predict(X_test, True, True)\n",
    "    r_hat = compute_rhat_regression(raw_preds, sampling_configs[\"num_chains\"])\n",
    "    print(\"R-hat: mean {:.4f} std {:.4f}\".format(float(r_hat.mean()), float(r_hat.std())))\n",
    "\n",
    "    rmse = uncertainty_metrics.rmse(pred_mean, y_test)\n",
    "    nll = uncertainty_metrics.gaussian_nll(y_test, pred_mean, pred_var)\n",
    "    print(\"> RMSE = {:.4f} | NLL = {:.4f}\".format(rmse, nll))\n",
    "    results['rmse'].append(rmse)\n",
    "    results['nll'].append(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(os.path.join(out_dir, \"optim_results.csv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results\n",
      "> RMSE: mean 2.7970e+00; std 9.1485e-01 | NLL: mean 2.4699e+00 std 1.4601e-01\n"
     ]
    }
   ],
   "source": [
    "print(\"Final results\")\n",
    "print(\"> RMSE: mean {:.4e}; std {:.4e} | NLL: mean {:.4e} std {:.4e}\".format(\n",
    "        float(result_df['rmse'].mean()), float(result_df['rmse'].std()),\n",
    "        float(result_df['nll'].mean()), float(result_df['nll'].std())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Standard Gaussian Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading split 0 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4463e+00 RMSE = 2.7549e+00 \n",
      "Samples #    10 : NLL =  2.4335e+00 RMSE = 2.7280e+00 \n",
      "Samples #    15 : NLL =  2.4278e+00 RMSE = 2.7117e+00 \n",
      "Samples #    20 : NLL =  2.4211e+00 RMSE = 2.6928e+00 \n",
      "Samples #    25 : NLL =  2.4226e+00 RMSE = 2.7005e+00 \n",
      "Samples #    30 : NLL =  2.4209e+00 RMSE = 2.6855e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4237e+00 RMSE = 2.6917e+00 \n",
      "Samples #    40 : NLL =  2.4231e+00 RMSE = 2.6914e+00 \n",
      "Samples #    45 : NLL =  2.4221e+00 RMSE = 2.6894e+00 \n",
      "Samples #    50 : NLL =  2.4220e+00 RMSE = 2.6891e+00 \n",
      "Samples #    55 : NLL =  2.4198e+00 RMSE = 2.6845e+00 \n",
      "Samples #    60 : NLL =  2.4207e+00 RMSE = 2.6863e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4220e+00 RMSE = 2.6874e+00 \n",
      "Samples #    70 : NLL =  2.4218e+00 RMSE = 2.6851e+00 \n",
      "Samples #    75 : NLL =  2.4213e+00 RMSE = 2.6863e+00 \n",
      "Samples #    80 : NLL =  2.4212e+00 RMSE = 2.6887e+00 \n",
      "Samples #    85 : NLL =  2.4204e+00 RMSE = 2.6864e+00 \n",
      "Samples #    90 : NLL =  2.4210e+00 RMSE = 2.6884e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4208e+00 RMSE = 2.6875e+00 \n",
      "Samples #   100 : NLL =  2.4208e+00 RMSE = 2.6899e+00 \n",
      "Samples #   105 : NLL =  2.4211e+00 RMSE = 2.6887e+00 \n",
      "Samples #   110 : NLL =  2.4207e+00 RMSE = 2.6872e+00 \n",
      "Samples #   115 : NLL =  2.4211e+00 RMSE = 2.6876e+00 \n",
      "Samples #   120 : NLL =  2.4213e+00 RMSE = 2.6882e+00 \n",
      "R-hat: mean 0.9992 std 0.0134\n",
      "> RMSE = 2.5470 | NLL = 2.3949\n",
      "Loading split 1 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4503e+00 RMSE = 2.8089e+00 \n",
      "Samples #    10 : NLL =  2.4441e+00 RMSE = 2.7530e+00 \n",
      "Samples #    15 : NLL =  2.4306e+00 RMSE = 2.7254e+00 \n",
      "Samples #    20 : NLL =  2.4261e+00 RMSE = 2.7101e+00 \n",
      "Samples #    25 : NLL =  2.4279e+00 RMSE = 2.7042e+00 \n",
      "Samples #    30 : NLL =  2.4260e+00 RMSE = 2.6969e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4243e+00 RMSE = 2.6924e+00 \n",
      "Samples #    40 : NLL =  2.4234e+00 RMSE = 2.6901e+00 \n",
      "Samples #    45 : NLL =  2.4213e+00 RMSE = 2.6844e+00 \n",
      "Samples #    50 : NLL =  2.4197e+00 RMSE = 2.6807e+00 \n",
      "Samples #    55 : NLL =  2.4183e+00 RMSE = 2.6786e+00 \n",
      "Samples #    60 : NLL =  2.4181e+00 RMSE = 2.6752e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4189e+00 RMSE = 2.6780e+00 \n",
      "Samples #    70 : NLL =  2.4169e+00 RMSE = 2.6776e+00 \n",
      "Samples #    75 : NLL =  2.4167e+00 RMSE = 2.6794e+00 \n",
      "Samples #    80 : NLL =  2.4172e+00 RMSE = 2.6803e+00 \n",
      "Samples #    85 : NLL =  2.4177e+00 RMSE = 2.6807e+00 \n",
      "Samples #    90 : NLL =  2.4175e+00 RMSE = 2.6799e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4171e+00 RMSE = 2.6785e+00 \n",
      "Samples #   100 : NLL =  2.4169e+00 RMSE = 2.6787e+00 \n",
      "Samples #   105 : NLL =  2.4170e+00 RMSE = 2.6813e+00 \n",
      "Samples #   110 : NLL =  2.4170e+00 RMSE = 2.6824e+00 \n",
      "Samples #   115 : NLL =  2.4171e+00 RMSE = 2.6832e+00 \n",
      "Samples #   120 : NLL =  2.4169e+00 RMSE = 2.6823e+00 \n",
      "R-hat: mean 1.0040 std 0.0163\n",
      "> RMSE = 2.6648 | NLL = 2.4296\n",
      "Loading split 2 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4266e+00 RMSE = 2.7003e+00 \n",
      "Samples #    10 : NLL =  2.4250e+00 RMSE = 2.7152e+00 \n",
      "Samples #    15 : NLL =  2.4212e+00 RMSE = 2.6953e+00 \n",
      "Samples #    20 : NLL =  2.4208e+00 RMSE = 2.6928e+00 \n",
      "Samples #    25 : NLL =  2.4221e+00 RMSE = 2.6956e+00 \n",
      "Samples #    30 : NLL =  2.4219e+00 RMSE = 2.6991e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4214e+00 RMSE = 2.7009e+00 \n",
      "Samples #    40 : NLL =  2.4220e+00 RMSE = 2.7058e+00 \n",
      "Samples #    45 : NLL =  2.4215e+00 RMSE = 2.7029e+00 \n",
      "Samples #    50 : NLL =  2.4214e+00 RMSE = 2.7007e+00 \n",
      "Samples #    55 : NLL =  2.4210e+00 RMSE = 2.6979e+00 \n",
      "Samples #    60 : NLL =  2.4225e+00 RMSE = 2.6984e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4225e+00 RMSE = 2.6967e+00 \n",
      "Samples #    70 : NLL =  2.4223e+00 RMSE = 2.6982e+00 \n",
      "Samples #    75 : NLL =  2.4219e+00 RMSE = 2.7007e+00 \n",
      "Samples #    80 : NLL =  2.4238e+00 RMSE = 2.7069e+00 \n",
      "Samples #    85 : NLL =  2.4244e+00 RMSE = 2.7102e+00 \n",
      "Samples #    90 : NLL =  2.4238e+00 RMSE = 2.7089e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4231e+00 RMSE = 2.7098e+00 \n",
      "Samples #   100 : NLL =  2.4228e+00 RMSE = 2.7089e+00 \n",
      "Samples #   105 : NLL =  2.4232e+00 RMSE = 2.7077e+00 \n",
      "Samples #   110 : NLL =  2.4234e+00 RMSE = 2.7087e+00 \n",
      "Samples #   115 : NLL =  2.4228e+00 RMSE = 2.7084e+00 \n",
      "Samples #   120 : NLL =  2.4228e+00 RMSE = 2.7085e+00 \n",
      "R-hat: mean 1.0034 std 0.0135\n",
      "> RMSE = 2.4642 | NLL = 2.3709\n",
      "Loading split 3 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4145e+00 RMSE = 2.7100e+00 \n",
      "Samples #    10 : NLL =  2.4114e+00 RMSE = 2.6935e+00 \n",
      "Samples #    15 : NLL =  2.4152e+00 RMSE = 2.6949e+00 \n",
      "Samples #    20 : NLL =  2.4062e+00 RMSE = 2.6783e+00 \n",
      "Samples #    25 : NLL =  2.4064e+00 RMSE = 2.6803e+00 \n",
      "Samples #    30 : NLL =  2.4083e+00 RMSE = 2.6851e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4082e+00 RMSE = 2.6782e+00 \n",
      "Samples #    40 : NLL =  2.4087e+00 RMSE = 2.6748e+00 \n",
      "Samples #    45 : NLL =  2.4108e+00 RMSE = 2.6820e+00 \n",
      "Samples #    50 : NLL =  2.4110e+00 RMSE = 2.6850e+00 \n",
      "Samples #    55 : NLL =  2.4112e+00 RMSE = 2.6844e+00 \n",
      "Samples #    60 : NLL =  2.4099e+00 RMSE = 2.6836e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4098e+00 RMSE = 2.6848e+00 \n",
      "Samples #    70 : NLL =  2.4089e+00 RMSE = 2.6821e+00 \n",
      "Samples #    75 : NLL =  2.4097e+00 RMSE = 2.6811e+00 \n",
      "Samples #    80 : NLL =  2.4094e+00 RMSE = 2.6812e+00 \n",
      "Samples #    85 : NLL =  2.4092e+00 RMSE = 2.6781e+00 \n",
      "Samples #    90 : NLL =  2.4090e+00 RMSE = 2.6759e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4086e+00 RMSE = 2.6741e+00 \n",
      "Samples #   100 : NLL =  2.4081e+00 RMSE = 2.6719e+00 \n",
      "Samples #   105 : NLL =  2.4086e+00 RMSE = 2.6741e+00 \n",
      "Samples #   110 : NLL =  2.4088e+00 RMSE = 2.6747e+00 \n",
      "Samples #   115 : NLL =  2.4088e+00 RMSE = 2.6738e+00 \n",
      "Samples #   120 : NLL =  2.4082e+00 RMSE = 2.6719e+00 \n",
      "R-hat: mean 1.0054 std 0.0203\n",
      "> RMSE = 2.5669 | NLL = 2.3812\n",
      "Loading split 4 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.3684e+00 RMSE = 2.5726e+00 \n",
      "Samples #    10 : NLL =  2.3702e+00 RMSE = 2.5634e+00 \n",
      "Samples #    15 : NLL =  2.3702e+00 RMSE = 2.5638e+00 \n",
      "Samples #    20 : NLL =  2.3706e+00 RMSE = 2.5638e+00 \n",
      "Samples #    25 : NLL =  2.3720e+00 RMSE = 2.5645e+00 \n",
      "Samples #    30 : NLL =  2.3756e+00 RMSE = 2.5712e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.3755e+00 RMSE = 2.5705e+00 \n",
      "Samples #    40 : NLL =  2.3760e+00 RMSE = 2.5730e+00 \n",
      "Samples #    45 : NLL =  2.3752e+00 RMSE = 2.5695e+00 \n",
      "Samples #    50 : NLL =  2.3745e+00 RMSE = 2.5682e+00 \n",
      "Samples #    55 : NLL =  2.3738e+00 RMSE = 2.5661e+00 \n",
      "Samples #    60 : NLL =  2.3738e+00 RMSE = 2.5636e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.3734e+00 RMSE = 2.5625e+00 \n",
      "Samples #    70 : NLL =  2.3739e+00 RMSE = 2.5663e+00 \n",
      "Samples #    75 : NLL =  2.3739e+00 RMSE = 2.5686e+00 \n",
      "Samples #    80 : NLL =  2.3745e+00 RMSE = 2.5706e+00 \n",
      "Samples #    85 : NLL =  2.3747e+00 RMSE = 2.5714e+00 \n",
      "Samples #    90 : NLL =  2.3745e+00 RMSE = 2.5703e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.3741e+00 RMSE = 2.5687e+00 \n",
      "Samples #   100 : NLL =  2.3740e+00 RMSE = 2.5705e+00 \n",
      "Samples #   105 : NLL =  2.3741e+00 RMSE = 2.5698e+00 \n",
      "Samples #   110 : NLL =  2.3744e+00 RMSE = 2.5691e+00 \n",
      "Samples #   115 : NLL =  2.3751e+00 RMSE = 2.5691e+00 \n",
      "Samples #   120 : NLL =  2.3753e+00 RMSE = 2.5704e+00 \n",
      "R-hat: mean 0.9978 std 0.0094\n",
      "> RMSE = 4.2503 | NLL = 2.9322\n",
      "Loading split 5 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4416e+00 RMSE = 2.7880e+00 \n",
      "Samples #    10 : NLL =  2.4306e+00 RMSE = 2.7368e+00 \n",
      "Samples #    15 : NLL =  2.4370e+00 RMSE = 2.7467e+00 \n",
      "Samples #    20 : NLL =  2.4306e+00 RMSE = 2.7351e+00 \n",
      "Samples #    25 : NLL =  2.4316e+00 RMSE = 2.7394e+00 \n",
      "Samples #    30 : NLL =  2.4301e+00 RMSE = 2.7363e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4301e+00 RMSE = 2.7388e+00 \n",
      "Samples #    40 : NLL =  2.4286e+00 RMSE = 2.7326e+00 \n",
      "Samples #    45 : NLL =  2.4290e+00 RMSE = 2.7319e+00 \n",
      "Samples #    50 : NLL =  2.4247e+00 RMSE = 2.7268e+00 \n",
      "Samples #    55 : NLL =  2.4254e+00 RMSE = 2.7269e+00 \n",
      "Samples #    60 : NLL =  2.4257e+00 RMSE = 2.7288e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4260e+00 RMSE = 2.7322e+00 \n",
      "Samples #    70 : NLL =  2.4236e+00 RMSE = 2.7289e+00 \n",
      "Samples #    75 : NLL =  2.4240e+00 RMSE = 2.7289e+00 \n",
      "Samples #    80 : NLL =  2.4249e+00 RMSE = 2.7306e+00 \n",
      "Samples #    85 : NLL =  2.4252e+00 RMSE = 2.7301e+00 \n",
      "Samples #    90 : NLL =  2.4246e+00 RMSE = 2.7296e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4247e+00 RMSE = 2.7316e+00 \n",
      "Samples #   100 : NLL =  2.4243e+00 RMSE = 2.7309e+00 \n",
      "Samples #   105 : NLL =  2.4249e+00 RMSE = 2.7321e+00 \n",
      "Samples #   110 : NLL =  2.4250e+00 RMSE = 2.7326e+00 \n",
      "Samples #   115 : NLL =  2.4246e+00 RMSE = 2.7325e+00 \n",
      "Samples #   120 : NLL =  2.4247e+00 RMSE = 2.7323e+00 \n",
      "R-hat: mean 1.0028 std 0.0150\n",
      "> RMSE = 2.2998 | NLL = 2.3237\n",
      "Loading split 6 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4298e+00 RMSE = 2.7123e+00 \n",
      "Samples #    10 : NLL =  2.4342e+00 RMSE = 2.7371e+00 \n",
      "Samples #    15 : NLL =  2.4357e+00 RMSE = 2.7460e+00 \n",
      "Samples #    20 : NLL =  2.4332e+00 RMSE = 2.7303e+00 \n",
      "Samples #    25 : NLL =  2.4314e+00 RMSE = 2.7210e+00 \n",
      "Samples #    30 : NLL =  2.4345e+00 RMSE = 2.7260e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4328e+00 RMSE = 2.7223e+00 \n",
      "Samples #    40 : NLL =  2.4347e+00 RMSE = 2.7211e+00 \n",
      "Samples #    45 : NLL =  2.4336e+00 RMSE = 2.7179e+00 \n",
      "Samples #    50 : NLL =  2.4342e+00 RMSE = 2.7209e+00 \n",
      "Samples #    55 : NLL =  2.4339e+00 RMSE = 2.7214e+00 \n",
      "Samples #    60 : NLL =  2.4336e+00 RMSE = 2.7199e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4335e+00 RMSE = 2.7177e+00 \n",
      "Samples #    70 : NLL =  2.4314e+00 RMSE = 2.7129e+00 \n",
      "Samples #    75 : NLL =  2.4302e+00 RMSE = 2.7107e+00 \n",
      "Samples #    80 : NLL =  2.4294e+00 RMSE = 2.7099e+00 \n",
      "Samples #    85 : NLL =  2.4293e+00 RMSE = 2.7099e+00 \n",
      "Samples #    90 : NLL =  2.4293e+00 RMSE = 2.7104e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4294e+00 RMSE = 2.7094e+00 \n",
      "Samples #   100 : NLL =  2.4302e+00 RMSE = 2.7105e+00 \n",
      "Samples #   105 : NLL =  2.4305e+00 RMSE = 2.7104e+00 \n",
      "Samples #   110 : NLL =  2.4304e+00 RMSE = 2.7112e+00 \n",
      "Samples #   115 : NLL =  2.4303e+00 RMSE = 2.7104e+00 \n",
      "Samples #   120 : NLL =  2.4298e+00 RMSE = 2.7093e+00 \n",
      "R-hat: mean 1.0130 std 0.0203\n",
      "> RMSE = 1.9066 | NLL = 2.2692\n",
      "Loading split 7 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.4252e+00 RMSE = 2.7455e+00 \n",
      "Samples #    10 : NLL =  2.4226e+00 RMSE = 2.7216e+00 \n",
      "Samples #    15 : NLL =  2.4249e+00 RMSE = 2.7323e+00 \n",
      "Samples #    20 : NLL =  2.4305e+00 RMSE = 2.7476e+00 \n",
      "Samples #    25 : NLL =  2.4282e+00 RMSE = 2.7329e+00 \n",
      "Samples #    30 : NLL =  2.4235e+00 RMSE = 2.7247e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.4234e+00 RMSE = 2.7184e+00 \n",
      "Samples #    40 : NLL =  2.4213e+00 RMSE = 2.7117e+00 \n",
      "Samples #    45 : NLL =  2.4206e+00 RMSE = 2.7060e+00 \n",
      "Samples #    50 : NLL =  2.4203e+00 RMSE = 2.7013e+00 \n",
      "Samples #    55 : NLL =  2.4195e+00 RMSE = 2.6989e+00 \n",
      "Samples #    60 : NLL =  2.4186e+00 RMSE = 2.6971e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.4168e+00 RMSE = 2.6954e+00 \n",
      "Samples #    70 : NLL =  2.4173e+00 RMSE = 2.6954e+00 \n",
      "Samples #    75 : NLL =  2.4168e+00 RMSE = 2.6921e+00 \n",
      "Samples #    80 : NLL =  2.4167e+00 RMSE = 2.6904e+00 \n",
      "Samples #    85 : NLL =  2.4165e+00 RMSE = 2.6900e+00 \n",
      "Samples #    90 : NLL =  2.4166e+00 RMSE = 2.6889e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.4163e+00 RMSE = 2.6861e+00 \n",
      "Samples #   100 : NLL =  2.4162e+00 RMSE = 2.6857e+00 \n",
      "Samples #   105 : NLL =  2.4150e+00 RMSE = 2.6826e+00 \n",
      "Samples #   110 : NLL =  2.4151e+00 RMSE = 2.6825e+00 \n",
      "Samples #   115 : NLL =  2.4157e+00 RMSE = 2.6841e+00 \n",
      "Samples #   120 : NLL =  2.4153e+00 RMSE = 2.6824e+00 \n",
      "R-hat: mean 1.0018 std 0.0158\n",
      "> RMSE = 3.5748 | NLL = 2.6458\n",
      "Loading split 8 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.3893e+00 RMSE = 2.6014e+00 \n",
      "Samples #    10 : NLL =  2.3893e+00 RMSE = 2.5954e+00 \n",
      "Samples #    15 : NLL =  2.3902e+00 RMSE = 2.5921e+00 \n",
      "Samples #    20 : NLL =  2.3846e+00 RMSE = 2.5959e+00 \n",
      "Samples #    25 : NLL =  2.3835e+00 RMSE = 2.5813e+00 \n",
      "Samples #    30 : NLL =  2.3837e+00 RMSE = 2.5834e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.3847e+00 RMSE = 2.5853e+00 \n",
      "Samples #    40 : NLL =  2.3838e+00 RMSE = 2.5818e+00 \n",
      "Samples #    45 : NLL =  2.3847e+00 RMSE = 2.5835e+00 \n",
      "Samples #    50 : NLL =  2.3851e+00 RMSE = 2.5804e+00 \n",
      "Samples #    55 : NLL =  2.3851e+00 RMSE = 2.5803e+00 \n",
      "Samples #    60 : NLL =  2.3842e+00 RMSE = 2.5762e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.3852e+00 RMSE = 2.5779e+00 \n",
      "Samples #    70 : NLL =  2.3849e+00 RMSE = 2.5777e+00 \n",
      "Samples #    75 : NLL =  2.3853e+00 RMSE = 2.5799e+00 \n",
      "Samples #    80 : NLL =  2.3861e+00 RMSE = 2.5808e+00 \n",
      "Samples #    85 : NLL =  2.3862e+00 RMSE = 2.5801e+00 \n",
      "Samples #    90 : NLL =  2.3859e+00 RMSE = 2.5771e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.3856e+00 RMSE = 2.5777e+00 \n",
      "Samples #   100 : NLL =  2.3855e+00 RMSE = 2.5768e+00 \n",
      "Samples #   105 : NLL =  2.3855e+00 RMSE = 2.5791e+00 \n",
      "Samples #   110 : NLL =  2.3846e+00 RMSE = 2.5761e+00 \n",
      "Samples #   115 : NLL =  2.3844e+00 RMSE = 2.5752e+00 \n",
      "Samples #   120 : NLL =  2.3836e+00 RMSE = 2.5737e+00 \n",
      "R-hat: mean 1.0028 std 0.0122\n",
      "> RMSE = 3.7176 | NLL = 2.7335\n",
      "Loading split 9 of boston dataset\n",
      "Chain: 0\n",
      "Samples #     5 : NLL =  2.3973e+00 RMSE = 2.6234e+00 \n",
      "Samples #    10 : NLL =  2.3893e+00 RMSE = 2.5847e+00 \n",
      "Samples #    15 : NLL =  2.3860e+00 RMSE = 2.5819e+00 \n",
      "Samples #    20 : NLL =  2.3820e+00 RMSE = 2.5653e+00 \n",
      "Samples #    25 : NLL =  2.3792e+00 RMSE = 2.5568e+00 \n",
      "Samples #    30 : NLL =  2.3791e+00 RMSE = 2.5522e+00 \n",
      "Chain: 1\n",
      "Samples #    35 : NLL =  2.3787e+00 RMSE = 2.5479e+00 \n",
      "Samples #    40 : NLL =  2.3788e+00 RMSE = 2.5481e+00 \n",
      "Samples #    45 : NLL =  2.3796e+00 RMSE = 2.5514e+00 \n",
      "Samples #    50 : NLL =  2.3789e+00 RMSE = 2.5519e+00 \n",
      "Samples #    55 : NLL =  2.3792e+00 RMSE = 2.5505e+00 \n",
      "Samples #    60 : NLL =  2.3788e+00 RMSE = 2.5495e+00 \n",
      "Chain: 2\n",
      "Samples #    65 : NLL =  2.3782e+00 RMSE = 2.5468e+00 \n",
      "Samples #    70 : NLL =  2.3777e+00 RMSE = 2.5447e+00 \n",
      "Samples #    75 : NLL =  2.3772e+00 RMSE = 2.5433e+00 \n",
      "Samples #    80 : NLL =  2.3784e+00 RMSE = 2.5474e+00 \n",
      "Samples #    85 : NLL =  2.3775e+00 RMSE = 2.5460e+00 \n",
      "Samples #    90 : NLL =  2.3771e+00 RMSE = 2.5431e+00 \n",
      "Chain: 3\n",
      "Samples #    95 : NLL =  2.3767e+00 RMSE = 2.5404e+00 \n",
      "Samples #   100 : NLL =  2.3768e+00 RMSE = 2.5418e+00 \n",
      "Samples #   105 : NLL =  2.3767e+00 RMSE = 2.5420e+00 \n",
      "Samples #   110 : NLL =  2.3768e+00 RMSE = 2.5429e+00 \n",
      "Samples #   115 : NLL =  2.3767e+00 RMSE = 2.5425e+00 \n",
      "Samples #   120 : NLL =  2.3757e+00 RMSE = 2.5389e+00 \n",
      "R-hat: mean 1.0092 std 0.0225\n",
      "> RMSE = 5.3246 | NLL = 3.1874\n"
     ]
    }
   ],
   "source": [
    "results = {\"rmse\": [], \"nll\": []}\n",
    "\n",
    "for split_id in range(n_splits):\n",
    "    print(\"Loading split {} of {} dataset\".format(split_id, dataset))\n",
    "    saved_dir = os.path.join(out_dir, str(split_id))\n",
    "    \n",
    "    # Load the dataset\n",
    "    X_train, y_train, X_test, y_test = util.load_uci_data(\n",
    "            data_dir, split_id, dataset)\n",
    "    input_dim, output_dim = int(X_train.shape[-1]), 1\n",
    "    \n",
    "    # Initialize the neural network and likelihood modules\n",
    "    net = MLP(input_dim, output_dim, [n_units] * n_hidden, activation_fn)\n",
    "    likelihood = LikGaussian(noise_var)\n",
    "    \n",
    "    # Initialize the standard gaussian prior\n",
    "    prior = FixedGaussianPrior(std=1.0)\n",
    "    \n",
    "    # Initialize bayesian neural network with SGHMC sampler\n",
    "    saved_dir = os.path.join(out_dir, str(split_id))\n",
    "    bayes_net = RegressionNet(net, likelihood, prior, saved_dir, n_gpu=0)\n",
    "    \n",
    "    # Start sampling\n",
    "    bayes_net.sample_multi_chains(X_train, y_train, **sampling_configs)\n",
    "    pred_mean, pred_var, preds, raw_preds = bayes_net.predict(X_test, True, True)\n",
    "    r_hat = compute_rhat_regression(raw_preds, sampling_configs[\"num_chains\"])\n",
    "    print(\"R-hat: mean {:.4f} std {:.4f}\".format(float(r_hat.mean()), float(r_hat.std())))\n",
    "\n",
    "    rmse = uncertainty_metrics.rmse(pred_mean, y_test)\n",
    "    nll = uncertainty_metrics.gaussian_nll(y_test, pred_mean, pred_var)\n",
    "    print(\"> RMSE = {:.4f} | NLL = {:.4f}\".format(rmse, nll))\n",
    "    results['rmse'].append(rmse)\n",
    "    results['nll'].append(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(results)\n",
    "result_df.to_csv(os.path.join(out_dir, \"std_results.csv\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results\n",
      "> RMSE: mean 3.1317e+00; std 1.0602e+00 | NLL: mean 2.5668e+00 std 3.0216e-01\n"
     ]
    }
   ],
   "source": [
    "print(\"Final results\")\n",
    "print(\"> RMSE: mean {:.4e}; std {:.4e} | NLL: mean {:.4e} std {:.4e}\".format(\n",
    "        float(result_df['rmse'].mean()), float(result_df['rmse'].std()),\n",
    "        float(result_df['nll'].mean()), float(result_df['nll'].std())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
